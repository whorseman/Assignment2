{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whorseman/Assignments/blob/main/homework_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following assignment consists of a theoretical part (learning portfolio) and a practical part (assignment). The goal is to build a classification model that predicts from which subject area a certain abstract originates. The plan would be that next week we will discuss your learnings from the theory part, that means you are relatively free to fill your Learning Portfolio on this new topic and in two weeks we will discuss your solutions of the Classification Model.\n",
        "\n",
        "#Theory part (filling your Learning Portfolio, May 10)\n",
        "\n",
        "In preparation for the practical part, I ask you to familiarize yourself with the following resources in the next week:\n",
        "\n",
        "1) Please watch the following video:\n",
        "\n",
        "https://course.fast.ai/Lessons/lesson4.html\n",
        "\n",
        "You are also welcome to watch the accompanying Kaggle notebook if you like the video.\n",
        "\n",
        "2) In addition to the video, I recommend you to read the first chapters of the course\n",
        "\n",
        "https://huggingface.co/learn/nlp-course/chapter1/1\n",
        "\n",
        "\n",
        "Try to understand principle processes and log them in your learning portfolio! A few suggestions: What is a pre-trained NLP model? How do I load them? What is tokenization? What does fine-tuning mean? What types of NLP Models are there? What possibilities do I have with the Transformers package? etc...\n",
        "\n",
        "#Practical part (Assignment, May 17)\n",
        "\n",
        "1) Preprocessing: The data which I provide as zip in Olat must be processed first, that means we need a table which has the following form:\n",
        "\n",
        "Keywords | Title | Abstract | Research Field\n",
        "\n",
        "The research field is determined by the name of the file.\n",
        "\n",
        "2) We need a training dataset and a test dataset. My suggestion would be that for each research field we use the first 5700 lines for the training dataset and the last 300 lines for the test dataset. Please stick to this because then we can compare our models better!\n",
        "\n",
        "3) Please use a pre-trained model from huggingface to build a classification model that tries to predict the correct research field from the 26. Please calculate the accuracy and the overall accuracy for all research fields. If you solve this task in a group, you can also try different pre-trained models. In addition to the abstracts, you can also see if the model improves if you include keywords and titles.\n",
        "\n",
        "Some links, which can help you:\n",
        "\n",
        "https://huggingface.co/docs/transformers/training\n",
        "\n",
        "https://huggingface.co/docs/transformers/tasks/sequence_classification\n",
        "\n",
        "One last request: Please always use PyTorch and not TensorFlow!"
      ],
      "metadata": {
        "id": "Rv37EvemaCce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neuer Abschnitt"
      ],
      "metadata": {
        "id": "9c0s15nfuLEC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3iBC50ZNsBlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUi9az-cZ9zq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a01362-2af3-4a25-dd46-052e0968fc38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from google.colab import data_table\n",
        "import matplotlib.pyplot as plt\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dat = \"/content/drive/MyDrive/DIGO/data\"\n",
        "\n",
        "#create dataframe with columns Title, 'Title','Abstract','Author Keywords','Index Keywords', Research Field\n",
        "df0 = pd.DataFrame(columns =['Title','Abstract','Author Keywords','Index Keywords','Research Field'])\n",
        "\n",
        "#iterate through all csvs\n",
        "for f in os.listdir(dat):\n",
        "  cat = str(f)[:4]\n",
        "  try:\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/DIGO/data/\" + str(f))\n",
        "    #only keep necessary columns\n",
        "    df = df[['Title','Abstract','Author Keywords','Index Keywords']]\n",
        "    #add cat as the shit at the end you know category or something like this\n",
        "    df['Research Field'] = cat\n",
        "\n",
        "    #merge dataframe to df0\n",
        "    df0 = pd.concat([df0, df])\n",
        "  except:\n",
        "    print('hah ur data is gay')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21opqIQ7nvjY",
        "outputId": "fbff7c60-a507-46af-feb6-3f408642c321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hah ur data is gay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "#randomly split into train and test dataset with a 0.95/5 split\n",
        "train = df0.sample(frac = 0.95)\n",
        "test = df0.drop(train.index)\n",
        "\"\"\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df0, random_state = 42, test_size = 0.05)\n"
      ],
      "metadata": {
        "id": "H1H5La5z9Yhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['Research Field'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXDA8D2IZInB",
        "outputId": "f8bfa401-c882-46e2-c502-1f7b37609578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ENER    318\n",
              "PHAR    318\n",
              "MATE    316\n",
              "IMMU    316\n",
              "MEDI    311\n",
              "SOCI    308\n",
              "ECON    306\n",
              "PSYC    305\n",
              "NURS    305\n",
              "BUSI    304\n",
              "COMP    303\n",
              "DECI    302\n",
              "ARTS    298\n",
              "BIOC    295\n",
              "ENGI    295\n",
              "DENT    293\n",
              "EART    289\n",
              "NEUR    289\n",
              "CHEM    288\n",
              "AGRI    287\n",
              "PHYS    283\n",
              "CENG    282\n",
              "VETE    279\n",
              "ENVI    279\n",
              "HEAL    249\n",
              "MATH    212\n",
              "Name: Research Field, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Addition: Accuracy measures whether the research field with the highest probability value matches the target. With 26 research fields, it would also be interesting to know if the correct target is at least among the three highest probability values.\n",
        "\n",
        "$\\begin{pmatrix} A\\\\ B \\\\ C \\\\D \\\\E \\end{pmatrix} = \\begin{pmatrix} 0.1\\\\ 0.95 \\\\ 0.5 \\\\0.2 \\\\0.3 \\end{pmatrix} â†’ \\text{Choice}_1 = B, \\text{Choice}_3 = B,C,E$"
      ],
      "metadata": {
        "id": "Up3aCw__4f4d"
      }
    }
  ]
}